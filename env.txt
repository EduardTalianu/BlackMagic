# =============================================================================
# Kali-LLM-Web Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# LLM API Configuration (REQUIRED)
# -----------------------------------------------------------------------------
MOONSHOT_API_KEY=sk-...
LLM_BASE_URL=https://api.moonshot.ai/v1
LLM_MODEL=kimi-k2-0905-preview

# =============================================================================
# Kali-LLM-Web Environment Configuration
# Staggered Parallel Execution (2 nodes every 3 minutes)
# =============================================================================

# -----------------------------------------------------------------------------
# Flask Configuration
# -----------------------------------------------------------------------------
FLASK_ENV=development
FLASK_DEBUG=1
AUTO_CONTINUE_DELAY=10

# -----------------------------------------------------------------------------
# Staggered Parallel Execution (NEW ARCHITECTURE)
# -----------------------------------------------------------------------------

# Enable or disable parallel execution
# When true: sub-tasks start in staggered batches
# When false: sub-tasks run sequentially (one at a time)
PARALLEL_ENABLED=true

# Maximum worker pool size (soft limit)
# This is a HIGH value because staggering controls actual parallelism
# The system starts 2 nodes every 3 minutes, so this allows many nodes
# to be queued and running simultaneously
# Recommendation: Keep at 100+ for staggered execution
PARALLEL_MAX_WORKERS=100

# Maximum concurrent LLM API calls (CRITICAL SETTING)
# This is THE PRIMARY CONTROL for preventing 429 rate limit errors
# 
# How it works:
# - All nodes share a semaphore that allows only N concurrent LLM calls
# - When a node needs to call the LLM (for planning or verification),
#   it acquires a semaphore slot, makes the call, then releases
# - If all slots are taken, nodes wait until a slot becomes available
# 
# This setting does NOT affect how many nodes can RUN in parallel
# (that's controlled by staggering), but it DOES affect how many
# can make LLM API calls at the same time
#
# Adjust based on your API tier:
#   Free tier: 2-3 (very conservative)
#   Pro tier: 5-10 (recommended: 5)
#   Enterprise: 10-20
#
# WARNING: Setting this too high WILL cause 429 errors and retries
PARALLEL_MAX_LLM=5

# LLM Retry Configuration
# Number of retry attempts for failed LLM API calls
# Includes exponential backoff: 2s, 4s, 8s, 16s, 32s
LLM_MAX_RETRIES=5

# Base delay (seconds) for exponential backoff
# Actual delays: 2s, 4s, 8s, 16s, 32s
LLM_BASE_DELAY=2

# Docker Configuration
# Timeout for Docker exec operations (seconds)
DOCKER_TIMEOUT=90

# File Naming Strategy
# Use node-prefixed filenames to avoid collisions in parallel execution
# true: files named like "n123456_report.txt"
# false: files named like "report.txt" (may collide)
USE_NODE_PREFIXES=true

# Staggered Execution Settings (NEW)
# Controls how nodes are started over time
#
# STAGGER_BATCH_SIZE: How many nodes to start in each batch
# STAGGER_DELAY: How long to wait between batches (in seconds)
#
# Default: Start 2 nodes every 180 seconds (3 minutes)
#
# Examples:
#   Start 2 every 3 min: STAGGER_BATCH_SIZE=2, STAGGER_DELAY=180
#   Start 3 every 5 min: STAGGER_BATCH_SIZE=3, STAGGER_DELAY=300
#   Start 1 every 2 min: STAGGER_BATCH_SIZE=1, STAGGER_DELAY=120
STAGGER_BATCH_SIZE=2
STAGGER_DELAY=180

# -----------------------------------------------------------------------------
# How Settings Affect Execution
# -----------------------------------------------------------------------------
#
# MYTH: "PARALLEL_MAX_WORKERS and PARALLEL_MAX_LLM control how many 
#        branches the task tree has"
#
# REALITY: These settings do NOT control branching. The LLM planner
#          decides how many branches to create based on task complexity.
#
# What each setting actually controls:
#
# 1. PARALLEL_MAX_WORKERS (soft limit, default: 100)
#    - Size of ThreadPoolExecutor worker pool
#    - High value allows many nodes to queue and run
#    - Staggering (2 every 3 min) controls actual parallelism
#    - Only affects execution speed, not tree structure
#
# 2. PARALLEL_MAX_LLM (CRITICAL, default: 5)
#    - Semaphore controlling concurrent LLM API calls
#    - PRIMARY bottleneck preventing 429 rate limit errors
#    - Does NOT limit how many nodes run in parallel
#    - Only limits how many can call LLM API simultaneously
#    - A node can run for minutes without calling LLM (e.g., during
#      Docker command execution), so many nodes can run while only
#      a few hold LLM semaphore slots
#
# 3. STAGGER_BATCH_SIZE + STAGGER_DELAY (NEW)
#    - Controls node start timing
#    - 2 nodes every 3 minutes = sustainable parallel growth
#    - After 15 minutes: 10 nodes started
#    - After 30 minutes: 20 nodes started
#    - Each node can run for 5-30+ minutes
#    - Result: Many nodes running in parallel, but starts are controlled
#
# Example timeline:
#   T=0:00  -> Start nodes 1-2
#   T=3:00  -> Start nodes 3-4 (nodes 1-2 still running)
#   T=6:00  -> Start nodes 5-6 (nodes 1-4 still running)
#   T=9:00  -> Start nodes 7-8 (nodes 1-6 still running)
#   ...
#
# At T=30:00, you might have 20 nodes running simultaneously,
# but only 5 can make LLM calls at once (PARALLEL_MAX_LLM=5)
#
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Performance Tuning Guide
# -----------------------------------------------------------------------------
#
# For FAST execution (high-end system, good API limits):
#   PARALLEL_ENABLED=true
#   PARALLEL_MAX_WORKERS=100
#   PARALLEL_MAX_LLM=10
#   STAGGER_BATCH_SIZE=3
#   STAGGER_DELAY=120
#
# For STABLE execution (free API tier, want to avoid 429 errors):
#   PARALLEL_ENABLED=true
#   PARALLEL_MAX_WORKERS=50
#   PARALLEL_MAX_LLM=2
#   STAGGER_BATCH_SIZE=1
#   STAGGER_DELAY=300
#
# For BALANCED execution (RECOMMENDED):
#   PARALLEL_ENABLED=true
#   PARALLEL_MAX_WORKERS=100
#   PARALLEL_MAX_LLM=5
#   STAGGER_BATCH_SIZE=2
#   STAGGER_DELAY=180
#
# For SEQUENTIAL execution (no parallelism):
#   PARALLEL_ENABLED=false
#   (other settings ignored)
#
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Troubleshooting
# -----------------------------------------------------------------------------
#
# Problem: Getting 429 rate limit errors
# Solution: Decrease PARALLEL_MAX_LLM (e.g., from 5 to 3)
#
# Problem: Tasks start too slowly
# Solution: Decrease STAGGER_DELAY or increase STAGGER_BATCH_SIZE
#
# Problem: Docker daemon CPU at 100%
# Solution: Increase STAGGER_DELAY or decrease STAGGER_BATCH_SIZE
#
# Problem: Out of memory
# Solution: Decrease PARALLEL_MAX_WORKERS
#
# Problem: Tasks fail with timeouts
# Solution: Increase DOCKER_TIMEOUT or increase STAGGER_DELAY
#
# -----------------------------------------------------------------------------

# =============================================================================
# Usage Instructions
# =============================================================================
# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Edit .env and set your MOONSHOT_API_KEY
#
# 3. Adjust settings based on your API tier and system resources
#
# 4. Start the application:
#    docker-compose up --build
#
# 5. Monitor execution:
#    - Watch logs for stagger messages: "Starting batch 1/5: 2 nodes"
#    - Check for 429 errors: "Rate limited (429). Waiting..."
#    - Monitor node completion: "✓ n123456 completed (3/10)"
#
# 6. Adjust if needed:
#    - Too many 429 errors → Decrease PARALLEL_MAX_LLM
#    - Tasks too slow → Decrease STAGGER_DELAY
#    - System overloaded → Increase STAGGER_DELAY
#
# =============================================================================